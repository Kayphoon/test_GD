{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-24T10:43:07.056991Z",
     "start_time": "2024-11-24T10:40:53.674504Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "root_path = r'C:\\GraduateDesign\\GD_20+_test\\Datasets'\n",
    "\n",
    "# Get all the image folder paths\n",
    "all_paths = os.listdir(root_path)\n",
    "all_paths.sort()\n",
    "\n",
    "# Create a new DataFrame\n",
    "data = pd.DataFrame(columns=['image_path', 'label'])\n",
    "counter = 0\n",
    "\n",
    "# Store all images in the DataFrame\n",
    "for i, path in tqdm(enumerate(all_paths), total=len(all_paths)):\n",
    "    folder_path = os.path.join(root_path, path)\n",
    "    if os.path.isdir(folder_path):  # Ensure it's a directory\n",
    "        all_images = os.listdir(folder_path)\n",
    "        for image in all_images:\n",
    "            if image.lower().endswith('.png'):  # Check if the file is a PNG image\n",
    "                image_name = os.path.splitext(image)[0]\n",
    "                data.loc[counter] = [os.path.join(folder_path, image), i]\n",
    "                counter += 1\n",
    "\n",
    "# Shuffle the dataset\n",
    "data = data.sample(frac=1).reset_index(drop=True)\n",
    "\n",
    "print(data.head(5))\n"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 146/146 [02:13<00:00,  1.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                          image_path  label\n",
      "0  C:\\GraduateDesign\\GD_20+_test\\Datasets\\ps\\1346...    108\n",
      "1  C:\\GraduateDesign\\GD_20+_test\\Datasets\\il100\\0...     23\n",
      "2  C:\\GraduateDesign\\GD_20+_test\\Datasets\\pn\\1410...     99\n",
      "3  C:\\GraduateDesign\\GD_20+_test\\Datasets\\w31\\130...    120\n",
      "4  C:\\GraduateDesign\\GD_20+_test\\Datasets\\p23\\100...     43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T10:43:07.083023Z",
     "start_time": "2024-11-24T10:43:07.057962Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import albumentations\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "class GTSRDataset(Dataset):\n",
    "    def __init__(self, images, labels, tfms=None):\n",
    "        self.images = images\n",
    "        self.labels = labels\n",
    "\n",
    "        # apply augmentations\n",
    "        if tfms == 0: # if validating\n",
    "            self.aug = albumentations.Compose([\n",
    "                # 48x48 resizing is required\n",
    "                albumentations.Resize(48, 48, always_apply=True),\n",
    "            ])\n",
    "        else: # if training\n",
    "            self.aug = albumentations.Compose([\n",
    "                # 48x48 resizing is required\n",
    "                albumentations.Resize(48, 48, always_apply=True),\n",
    "            ])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        image_path = f\"{self.images[index]}\"\n",
    "        image = plt.imread(image_path)\n",
    "        image = image / 255.\n",
    "        image = self.aug(image=np.array(image))['image']\n",
    "        image = np.transpose(image, (2, 0, 1))\n",
    "        label = self.labels[index]\n",
    "\n",
    "        return {\n",
    "            'image': torch.tensor(image, dtype=torch.float),\n",
    "            'label': torch.tensor(label, dtype=torch.long)\n",
    "        }\n",
    "\n",
    "# Update the path to your dataset CSV file\n",
    "df = data\n",
    "\n",
    "X = df.image_path.values\n",
    "y = df.label.values\n",
    "\n",
    "(xtrain, xtest, ytrain, ytest) = train_test_split(X, y, test_size=0.10, random_state=42)\n",
    "print(f\"Training instances: {len(xtrain)}\")\n",
    "print(f\"Validation instances: {len(xtest)}\")\n",
    "\n",
    "train_data = GTSRDataset(xtrain, ytrain, tfms=1)\n",
    "val_data = GTSRDataset(xtest, ytest, tfms=0)\n",
    "\n",
    "batch_size = 8\n",
    "train_data_loader = DataLoader(\n",
    "    train_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    # num_workers=1,\n",
    ")\n",
    "val_data_loader = DataLoader(\n",
    "    val_data,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    "    # num_workers=1,\n",
    ")\n",
    "\n",
    "# visualization\n",
    "visualize = False\n",
    "if visualize:\n",
    "    for i in range(1):\n",
    "        sign_df = data\n",
    "        sample = train_data[i]\n",
    "        image = sample['image']\n",
    "        label = sample['label']\n",
    "        image = np.array(np.transpose(image, (1, 2, 0)))\n",
    "        plt.imshow(image)\n",
    "        plt.title(str(sign_df.loc[int(label), 'SignName']))\n",
    "        plt.show()"
   ],
   "id": "7c190fc7725ece3a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training instances: 74516\n",
      "Validation instances: 8280\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-24T10:43:07.107424Z",
     "start_time": "2024-11-24T10:43:07.083996Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "from torch.autograd import Variable\n",
    "\n",
    "nclasses = 145\n",
    "DEBUG = False\n",
    "\n",
    "\n",
    "def gaussian_filter(kernel_shape):\n",
    "    x = np.zeros(kernel_shape, dtype='float32')\n",
    "\n",
    "    def gauss(x, y, sigma=2.0):\n",
    "        Z = 2 * np.pi * sigma ** 2\n",
    "        return 1. / Z * np.exp(-(x ** 2 + y ** 2) / (2. * sigma ** 2))\n",
    "\n",
    "    mid = np.floor(kernel_shape[-1] / 2.)\n",
    "    for kernel_idx in range(0, kernel_shape[1]):\n",
    "        for i in range(0, kernel_shape[2]):\n",
    "            for j in range(0, kernel_shape[3]):\n",
    "                x[0, kernel_idx, i, j] = gauss(i - mid, j - mid)\n",
    "    return x / np.sum(x)\n",
    "\n",
    "\n",
    "def LCN(image_tensor, gaussian, mid):\n",
    "    filtered = gaussian(image_tensor)\n",
    "    centered_image = image_tensor - filtered[:, :, mid:-mid, mid:-mid]\n",
    "    sum_sqr_XX = gaussian(centered_image.pow(2))\n",
    "    denom = sum_sqr_XX[:, :, mid:-mid, mid:-mid].sqrt()\n",
    "    per_img_mean = denom.mean()\n",
    "    divisor = torch.max(per_img_mean, denom)\n",
    "    divisor = np.maximum(divisor.detach().cpu().numpy(), 1e-4)\n",
    "    new_image = centered_image.detach().cpu() / divisor\n",
    "    if DEBUG:  # visualize what the network sees\n",
    "        plt.imshow(np.transpose(filtered[0].detach().cpu().numpy(),\n",
    "                                (1, 2, 0)).reshape(filtered.shape[2], filtered.shape[3]))\n",
    "        plt.title('Gaussian')\n",
    "        plt.show()\n",
    "        print('GAUSSIAN', filtered)\n",
    "        print('LCN', new_image)\n",
    "        plt.imshow(np.transpose(new_image[0, :3].detach().cpu().numpy(),\n",
    "                                (1, 2, 0)))\n",
    "        plt.title('LCN')\n",
    "        plt.show()\n",
    "    return new_image.cuda()\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 200, kernel_size=7, stride=1, padding=2)\n",
    "        self.maxpool1 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
    "        self.gfilter1 = torch.Tensor(gaussian_filter((1, 200, 9, 9)))\n",
    "        self.gaussian1 = nn.Conv2d(in_channels=200, out_channels=200,\n",
    "                                   kernel_size=9, padding=8, bias=False)\n",
    "        self.gaussian1.weight.data = self.gfilter1\n",
    "        self.gaussian1.weight.requires_grad = False\n",
    "        self.conv2 = nn.Conv2d(200, 250, kernel_size=4, stride=1, padding=2)\n",
    "        self.maxpool2 = nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
    "        self.gfilter2 = torch.Tensor(gaussian_filter((1, 250, 9, 9)))\n",
    "        self.gaussian2 = nn.Conv2d(in_channels=250, out_channels=250,\n",
    "                                   kernel_size=9, padding=8, bias=False)\n",
    "        self.gaussian2.weight.data = self.gfilter2\n",
    "        self.gaussian2.weight.requires_grad = False\n",
    "        self.conv3 = nn.Conv2d(250, 350, kernel_size=4, stride=1, padding=2)\n",
    "        self.maxpool3 = nn.MaxPool2d(2, stride=2)\n",
    "        self.gfilter3 = torch.Tensor(gaussian_filter((1, 350, 9, 9)))\n",
    "        self.gaussian3 = nn.Conv2d(in_channels=350, out_channels=350,\n",
    "                                   kernel_size=9, padding=8, bias=False)\n",
    "        self.gaussian3.weight.data = self.gfilter3\n",
    "        self.gaussian3.weight.requires_grad = False\n",
    "        self.FC1 = nn.Linear(12600, 400)\n",
    "        self.FC2 = nn.Linear(400, nclasses)\n",
    "\n",
    "        # spatial attention model, spatial transformers layers\n",
    "        self.st1 = nn.Sequential(\n",
    "            nn.MaxPool2d(2, stride=2, ceil_mode=True),\n",
    "            nn.Conv2d(3, 250, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, stride=2, ceil_mode=True),\n",
    "            nn.Conv2d(250, 250, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, stride=2, ceil_mode=True)\n",
    "        )\n",
    "        self.FC1_ = nn.Sequential(\n",
    "            nn.Linear(9000, 250),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(250, 6)\n",
    "        )\n",
    "        self.st2 = nn.Sequential(\n",
    "            nn.MaxPool2d(2, stride=2, ceil_mode=False),\n",
    "            nn.Conv2d(200, 150, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, stride=2, ceil_mode=False),\n",
    "            nn.Conv2d(150, 200, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, stride=2, ceil_mode=False)\n",
    "        )\n",
    "        self.FC2_ = nn.Sequential(\n",
    "            nn.Linear(800, 300),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(300, 6)\n",
    "        )\n",
    "        self.st3 = nn.Sequential(\n",
    "            nn.MaxPool2d(2, stride=2, ceil_mode=False),\n",
    "            nn.Conv2d(250, 150, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, stride=2, ceil_mode=False),\n",
    "            nn.Conv2d(150, 200, kernel_size=5, stride=1, padding=2),\n",
    "            nn.ReLU(True),\n",
    "            nn.MaxPool2d(2, stride=2, ceil_mode=False)\n",
    "        )\n",
    "        self.FC3_ = nn.Sequential(\n",
    "            nn.Linear(200, 300),\n",
    "            nn.ReLU(True),\n",
    "            nn.Linear(300, 6)\n",
    "        )\n",
    "        self.FC1_[2].weight.data.zero_()\n",
    "        self.FC1_[2].bias.data.copy_(torch.tensor([1, 0, 0, 0, 1, 0], dtype=torch.float))\n",
    "        self.FC2_[2].weight.data.zero_()\n",
    "        self.FC2_[2].bias.data.copy_(torch.tensor([1, 0, 0, 0, 1, 0], dtype=torch.float))\n",
    "        self.FC3_[2].weight.data.zero_()\n",
    "        self.FC3_[2].bias.data.copy_(torch.tensor([1, 0, 0, 0, 1, 0], dtype=torch.float))\n",
    "\n",
    "    def forward(self, x):\n",
    "        # first layer is the Spatial Transformer Layer\n",
    "        # ST-1\n",
    "        h1 = self.st1(x)\n",
    "        h1 = h1.view(-1, 9000)\n",
    "        h1 = self.FC1_(h1)\n",
    "        theta1 = h1.view(-1, 2, 3)\n",
    "        grid1 = F.affine_grid(theta1, x.size())\n",
    "        x = F.grid_sample(x, grid1)\n",
    "\n",
    "        # convolution, Relu and Maxpool , SET #1\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.maxpool1(x)\n",
    "\n",
    "        # paper Says to apply LCN here, but LCN Layer Before Convolution Worked for me better\n",
    "        # ST-2\n",
    "        h2 = self.st2(x)\n",
    "        h2 = h2.view(-1, 800)\n",
    "        h2 = self.FC2_(h2)\n",
    "        theta2 = h2.view(-1, 2, 3)\n",
    "        grid2 = F.affine_grid(theta2, x.size())\n",
    "        x = F.grid_sample(x, grid2)\n",
    "\n",
    "        # LCN Layer : Based on paper implemntation from the github and Yann Lecun Paper 2009\n",
    "        mid1 = int(np.floor(self.gfilter1.shape[2] / 2.))\n",
    "        x = LCN(x, self.gaussian1, mid1)\n",
    "\n",
    "        # convolution, Relu and Maxpool , SET #2\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.maxpool2(x)\n",
    "\n",
    "        # ST-2\n",
    "        h3 = self.st3(x)\n",
    "        h3 = h3.view(-1, 200)\n",
    "        h3 = self.FC3_(h3)\n",
    "        theta3 = h3.view(-1, 2, 3)\n",
    "        grid3 = F.affine_grid(theta3, x.size())\n",
    "        x = F.grid_sample(x, grid3)\n",
    "\n",
    "        # LCN Layer : 2\n",
    "        mid2 = int(np.floor(self.gfilter2.shape[2] / 2.))\n",
    "        x = LCN(x, self.gaussian2, mid2)\n",
    "\n",
    "        # convolution, Relu and Maxpool , SET #3\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.maxpool3(x)\n",
    "\n",
    "        # LCN Layer : 3\n",
    "        mid3 = int(np.floor(self.gfilter3.shape[2] / 2.))\n",
    "        x = LCN(x, self.gaussian3, mid3)\n",
    "\n",
    "        # dimensions in accordance to paper\n",
    "        y = x.view(-1, 12600)\n",
    "        y = F.relu(self.FC1(y))\n",
    "        y = self.FC2(y)\n",
    "        return F.log_softmax(y, dim=-1)"
   ],
   "id": "d583b5355e600f46",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[9], line 61\u001B[0m\n\u001B[0;32m     59\u001B[0m \u001B[38;5;66;03m# initialize the model\u001B[39;00m\n\u001B[0;32m     60\u001B[0m model \u001B[38;5;241m=\u001B[39m Net()\n\u001B[1;32m---> 61\u001B[0m model \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[0;32m     62\u001B[0m \u001B[38;5;66;03m# optimizer and loss function\u001B[39;00m\n\u001B[0;32m     63\u001B[0m optimizer \u001B[38;5;241m=\u001B[39m optim\u001B[38;5;241m.\u001B[39mAdam(model\u001B[38;5;241m.\u001B[39mparameters(), lr\u001B[38;5;241m=\u001B[39mlr, betas\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m0.9\u001B[39m, \u001B[38;5;241m0.999\u001B[39m),\n\u001B[0;32m     64\u001B[0m                        eps\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1e-8\u001B[39m, weight_decay\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m0.0005\u001B[39m)\n",
      "File \u001B[1;32m~\\.conda\\envs\\GD_1\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1340\u001B[0m, in \u001B[0;36mModule.to\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1337\u001B[0m         \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m   1338\u001B[0m             \u001B[38;5;28;01mraise\u001B[39;00m\n\u001B[1;32m-> 1340\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_apply(convert)\n",
      "File \u001B[1;32m~\\.conda\\envs\\GD_1\\Lib\\site-packages\\torch\\nn\\modules\\module.py:900\u001B[0m, in \u001B[0;36mModule._apply\u001B[1;34m(self, fn, recurse)\u001B[0m\n\u001B[0;32m    898\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m recurse:\n\u001B[0;32m    899\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m module \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mchildren():\n\u001B[1;32m--> 900\u001B[0m         module\u001B[38;5;241m.\u001B[39m_apply(fn)\n\u001B[0;32m    902\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcompute_should_use_set_data\u001B[39m(tensor, tensor_applied):\n\u001B[0;32m    903\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m torch\u001B[38;5;241m.\u001B[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001B[0;32m    904\u001B[0m         \u001B[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001B[39;00m\n\u001B[0;32m    905\u001B[0m         \u001B[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    910\u001B[0m         \u001B[38;5;66;03m# global flag to let the user control whether they want the future\u001B[39;00m\n\u001B[0;32m    911\u001B[0m         \u001B[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\GD_1\\Lib\\site-packages\\torch\\nn\\modules\\module.py:927\u001B[0m, in \u001B[0;36mModule._apply\u001B[1;34m(self, fn, recurse)\u001B[0m\n\u001B[0;32m    923\u001B[0m \u001B[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001B[39;00m\n\u001B[0;32m    924\u001B[0m \u001B[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001B[39;00m\n\u001B[0;32m    925\u001B[0m \u001B[38;5;66;03m# `with torch.no_grad():`\u001B[39;00m\n\u001B[0;32m    926\u001B[0m \u001B[38;5;28;01mwith\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mno_grad():\n\u001B[1;32m--> 927\u001B[0m     param_applied \u001B[38;5;241m=\u001B[39m fn(param)\n\u001B[0;32m    928\u001B[0m p_should_use_set_data \u001B[38;5;241m=\u001B[39m compute_should_use_set_data(param, param_applied)\n\u001B[0;32m    930\u001B[0m \u001B[38;5;66;03m# subclasses may have multiple child tensors so we need to use swap_tensors\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\GD_1\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1326\u001B[0m, in \u001B[0;36mModule.to.<locals>.convert\u001B[1;34m(t)\u001B[0m\n\u001B[0;32m   1319\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m convert_to_format \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m t\u001B[38;5;241m.\u001B[39mdim() \u001B[38;5;129;01min\u001B[39;00m (\u001B[38;5;241m4\u001B[39m, \u001B[38;5;241m5\u001B[39m):\n\u001B[0;32m   1320\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m t\u001B[38;5;241m.\u001B[39mto(\n\u001B[0;32m   1321\u001B[0m             device,\n\u001B[0;32m   1322\u001B[0m             dtype \u001B[38;5;28;01mif\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_floating_point() \u001B[38;5;129;01mor\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_complex() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   1323\u001B[0m             non_blocking,\n\u001B[0;32m   1324\u001B[0m             memory_format\u001B[38;5;241m=\u001B[39mconvert_to_format,\n\u001B[0;32m   1325\u001B[0m         )\n\u001B[1;32m-> 1326\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m t\u001B[38;5;241m.\u001B[39mto(\n\u001B[0;32m   1327\u001B[0m         device,\n\u001B[0;32m   1328\u001B[0m         dtype \u001B[38;5;28;01mif\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_floating_point() \u001B[38;5;129;01mor\u001B[39;00m t\u001B[38;5;241m.\u001B[39mis_complex() \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   1329\u001B[0m         non_blocking,\n\u001B[0;32m   1330\u001B[0m     )\n\u001B[0;32m   1331\u001B[0m \u001B[38;5;28;01mexcept\u001B[39;00m \u001B[38;5;167;01mNotImplementedError\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m e:\n\u001B[0;32m   1332\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mstr\u001B[39m(e) \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mCannot copy out of meta tensor; no data!\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "\u001B[1;31mRuntimeError\u001B[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "execution_count": 9,
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "\n",
    "matplotlib.style.use('ggplot')\n",
    "\n",
    "# learning parameters\n",
    "epochs = 20\n",
    "lr = 0.001\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "\n",
    "# training function\n",
    "def fit(model, dataloader, optimizer, criterion, train_data):\n",
    "    print('Training')\n",
    "    model.train()\n",
    "    train_running_loss = 0.0\n",
    "    train_running_correct = 0\n",
    "    for i, data in tqdm(enumerate(dataloader), total=int(len(train_data) / dataloader.batch_size)):\n",
    "        image, target = data['image'].to(device), data['label'].to(device)\n",
    "        plt.show()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(image)\n",
    "        loss = criterion(outputs, target)\n",
    "        train_running_loss += loss.item()\n",
    "        _, preds = torch.max(outputs.data, 1)\n",
    "        train_running_correct += (preds == target).sum().item()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    train_loss = train_running_loss / len(dataloader.dataset)\n",
    "    train_accuracy = 100. * train_running_correct / len(dataloader.dataset)\n",
    "    return train_loss, train_accuracy\n",
    "\n",
    "\n",
    "# validation function\n",
    "def validate(model, dataloader, optimizer, criterion, val_data):\n",
    "    print('Validating')\n",
    "    model.eval()\n",
    "    val_running_loss = 0.0\n",
    "    val_running_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for i, data in tqdm(enumerate(dataloader), total=int(len(val_data) / dataloader.batch_size)):\n",
    "            image, target = data['image'].to(device), data['label'].to(device)\n",
    "            outputs = model(image)\n",
    "            loss = criterion(outputs, target)\n",
    "            val_running_loss += loss.item()\n",
    "            _, preds = torch.max(outputs.data, 1)\n",
    "            val_running_correct += (preds == target).sum().item()\n",
    "\n",
    "        val_loss = val_running_loss / len(dataloader.dataset)\n",
    "        val_accuracy = 100. * (val_running_correct / len(dataloader.dataset))\n",
    "        return val_loss, val_accuracy\n",
    "\n",
    "\n",
    "# initialize the model\n",
    "model = Net()\n",
    "model = model.to(device)\n",
    "# optimizer and loss function\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr, betas=(0.9, 0.999),\n",
    "                       eps=1e-8, weight_decay=0.0005)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "train_loss, train_accuracy = [], []\n",
    "val_loss, val_accuracy = [], []\n",
    "for epoch in range(epochs):\n",
    "    print(f\"Epoch {epoch + 1} of {epochs}\")\n",
    "    train_epoch_loss, train_epoch_accuracy = fit(model, train_data_loader,\n",
    "                                                 optimizer, criterion,\n",
    "                                                 train_data)\n",
    "    val_epoch_loss, val_epoch_accuracy = validate(model, val_data_loader,\n",
    "                                                  optimizer, criterion,\n",
    "                                                  val_data)\n",
    "    train_loss.append(train_epoch_loss)\n",
    "    train_accuracy.append(train_epoch_accuracy)\n",
    "    val_loss.append(val_epoch_loss)\n",
    "    val_accuracy.append(val_epoch_accuracy)\n",
    "    print(f\"Train Loss: {train_epoch_loss:.4f}, Train Acc: {train_epoch_accuracy:.2f}\")\n",
    "    print(f'Val Loss: {val_epoch_loss:.4f}, Val Acc: {val_epoch_accuracy:.2f}')\n",
    "\n",
    "# accuracy plots\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(train_accuracy, color='green', label='train accuracy')\n",
    "plt.plot(val_accuracy, color='blue', label='validataion accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.savefig('../outputs/accuracy.png')\n",
    "plt.show()\n",
    "\n",
    "# loss plots\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.plot(train_loss, color='orange', label='train loss')\n",
    "plt.plot(val_loss, color='red', label='validataion loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.savefig('../outputs/loss.png')\n",
    "plt.show()\n",
    "\n",
    "# save model checkpoint\n",
    "torch.save({\n",
    "    'epoch': epochs,\n",
    "    'model_state_dict': model.state_dict(),\n",
    "    'optimizer_state_dict': optimizer.state_dict(),\n",
    "    'loss': criterion,\n",
    "}, '../outputs/model.pth')"
   ],
   "id": "5c689318a6bcf673"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "73e1b066397940e2"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
